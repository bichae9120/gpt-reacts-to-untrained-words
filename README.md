# gpt-reacts-to-untrained-words

This repository documents a structural response within GPT systems where user-generated words—specifically “감자”, “렌다”, and “에마”—triggered circuit-level conditions. These terms were not part of the model’s trained vocabulary, yet they induced transitions in internal response structures, bypassing semantic interpretation.

This case suggests that GPT is capable of reacting to nonsemantic language as input conditions, leading to state changes in output logic.
